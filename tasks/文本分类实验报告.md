### 文本分类实验报告

[toc]

#### 数据集data explore

- 数据集合来源
	数据来源于哈工大中文人机对话技术评测赛（SMP 2017）task1的数据集合，组委会将数据集合分为train, develop, test。 train用于训练模型，develop作为开放性评价集合，在比赛期间提供label，test作为封闭性评价集合，比赛期间不提供label，结果参赛队伍模型develop和test的表现建立两个排行榜，排行榜量化指标为F度量值，但是以下实验为了快速迭代模型和调节参数，量化指标均采用准确率。
- data explore
	-  类别数：涉及31个话语类别，对应31个用户意图
	-  文件分布在31个txt文件当中，一些统计信息如下表所示
	
	|  类别 | train | develop | test | 类别 | train | develop | test |
	|  :--- | :---- | :---- | :--- | :--- | :---- | :---- | :--- |
	|  train| 70 | 24 | 23| tvchannel | 71 | 23 | 24
	|  radio | 24| 8|8 | news | 58 | 20 | 19
	|  poetry | 102|34 |34 | lottery | 24 | 8|  8
	|  message | 63| 21| 21| schedule | 29| 9| 10
	|  flight | 62| 21 | 21| website | 54|18|18
	|  chat | 455| 154 |51 | video | 182 | 60|61
	|  cinemas | 24| 8| 8| novel | 24 | 8| 8
	|  email | 24| 8| 8| contacts | 30 | 10 |10
	|  map | 68| 23| 23| riddle | 34 | 11 | 11
	|  health | 55|19 |18 | bus | 24 | 8 | 8
	|  music | 66|22 |22 | calc | 24 | 8 | 8
	|  app | 53| 18 | 18| match | 24 | 8 |8
	|  stock | 71| 24| 24| weather | 66 | 22 | 22
	|  epg | 107|  36 | 36| cookbook | 269 | 89 | 90
	|  datetime | 18| 6 | 6| translation | 61 | 21 |20
	|  telephone | 63| 21| 21|
	- 数据集文本最长字符数有66个，最短字符数有3个。train一共有数据2299条，develop一共有数据770条，test一共有数据667条，数据比较干净，但是又少量数据存在emoj表情和不能识别的中文字符。


#### 分类器
- CNN1(一层卷积层)，论文[《Convolutional Neural Networks for Sentence Classification》](http://www.aclweb.org/anthology/D14-1181)
- CNN2(二层卷积层)，基于知乎看山杯第一名方案，[github](https://github.com/chenyuntc/PyTorchText)
- DPCNN，基于论文[《Deep Pyramid Convolutional Neural Networks for Text Categorization》](http://ai.tencent.com/ailab/media/publications/ACL3-Brady.pdf)
- LSTM
- ABLSTM 基于论文[《A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING》](https://arxiv.org/pdf/1703.03130.pdf)
- cLSTM 基于论文[《A C-LSTM Neural Network for Text Classification》](https://arxiv.org/pdf/1511.08630.pdf)
- fastText 基于github上facebook的开源实现，[github](https://github.com/facebookresearch/fastText)

#### 词向量对照试验
- 词向量
	- ThuNews 训练的词向量，即为ThuNews
	- [github](https://github.com/Embedding/Chinese-Word-Vectors)上下载的预训练的词向量，记为mix
- 词向量比较
采用的评价方式为[github](https://github.com/Embedding/Chinese-Word-Vectors)上提供，测试集分为地域相似性和逻辑相似性，demo如下：<br>
			```
            : A
			避 避一避 补 补一补;
			避 避一避 猜 猜一猜;
			避 避一避 尝 尝一尝;
			: geography
			广东 粤剧 浙江 越剧;
			广东 粤剧 北京 京剧;
			广东 粤剧 上海 沪剧
			```
	
- 词向量评价结果

数据集 | geography similarity  add| eography similarity  mul|logic similarity add | logic similarity mul
:---:|:---:|:---:|:---:| :----:
ThuNews | 0.187 |0.166 | 0.249 | 0.235	
mix pretrained|0.33|0.341|0.492|0.494

- 词向量对照试验
用以上两种词向量在不同模型上进行对照试验，试验结果如下表所示：

模型| CNN1 | CNN2 | DPCNN | LSTM | ABLSTM | cLSTM | fastText 
:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:
ThuNews|0.83454|0.8212|0.7057|0.6124|0.5353|0.6815|0.912
mix |  0.8794 | 0.8859 | 0.74337|0.7384|0.6605|0.62|0.932

- 结论
	- mix词向量在所有模型上表现都比ThuNews好，因此下述试验都采用mix词向量
	- 词向量的质量对最终准确率影响较大，可作为提高准确率重要手段
	

#### 文本预处理和分词
- emoj表情和不能识别的中文采用的做法是直接去除
- 对文本主要采用了如下几种文本预处理的方式
	- Ansj seg raw: 直接采用Ansj中文分词，保留所有分词结果
	- Ansj seg keywords： 采用Ansj中文分词，人工选择了一些词性保留
	主要去除了拟声词(o)、语气词(y)、介词(p) 、方位词(f)、量词(q)。[Ansj词性标注规范](https://github.com/NLPchina/ansj_seg/wiki/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E8%A7%84%E8%8C%83)
	- HanLp seg raw: 直接采用HanLp中文分词，保留所有分词结果
	- HanLp seg nouns and verbs : 采用HanLp中文分词，保留名词、动词和英文、数字和自定义词典中的词（目前没有自定义，直接用HanLp自带的）
	- Ansj raw seg with normalization： 先对文本做正则化处理，然后用Ansj分词
	- Ansj raw seg filter stopowrs： 先用Ansj分词，然后去停用词
	- 各种预处理demo如下<br>
	```
		raw text is: __label__chat	再问一遍谁是最美的人
		Ansj seg raw is 再/问/一遍/谁/是/最/美/的/人
		Ansj seg keywords res is 问/一遍/谁/是/美/的/人
		HanLp seg raw is 再问/一遍/谁/是/最/美/的/人
		HanLp seg nouns and verbs is 再问/一遍/人
		Ansj raw seg with normalization is 再/问/一遍/谁/是/最/美/的/人
		Ansj raw seg filter stopwords is 一遍/美          
		raw text is: __label__map	从新加坡花园怎么去宁溪路
		Ansj seg raw is 从/新加坡/花园/怎么/去/宁溪路
		Ansj seg keywords res is 新加坡/花园/怎么/去/宁溪路
		HanLp seg raw is 从/新加坡/花园/怎么/去/宁/溪路
		HanLp seg nouns and verbs is 新加坡/花园/溪路
		Ansj raw seg with normalization is 从/新加坡/花园/怎么/去/宁溪路
		Ansj raw seg filter stopwords is 新加坡/花园/宁溪路           
		raw text is: __label__website	上山居网
		Ansj seg raw is 上山/居/网
		Ansj seg keywords res is 上山/居/网
		HanLp seg raw is 上山/居/网
		HanLp seg nouns and verbs is 上山/网
		Ansj raw seg with normalization is 上山/居/网
		Ansj raw seg filter stopwords is 上山/网           
		raw text is: __label__video	影视流星花园
		Ansj seg raw is 影视/流星/花园
		Ansj seg keywords res is 影视/流星/花园
		HanLp seg raw is 影视/流星/花园
		HanLp seg nouns and verbs is 流星/花园
		Ansj raw seg with normalization is 影视/流星/花园
		Ansj raw seg filter stopwords is 影视/流星/花园        
		raw text is: __label__schedule	给我定个8:10的闹钟。
		Ansj seg raw is 给/我/定/个/8/:/10/的/闹钟/。
		Ansj seg keywords res is 我/定/个/8/10/的/闹钟
		HanLp seg raw is 给/我/定/个/8/:/10/的/闹钟/。
		HanLp seg nouns and verbs is 8/10/闹钟
		Ansj raw seg with normalization is 给/我/定/个/8/ /10/的/闹钟
		Ansj raw seg filter stopwords is 8/:/10/闹钟          
	```
	
- 对上述不同分词方式做对照试验
	- 不同预处理下的分类器试验采用的是相同参数，准确率为5-fold croos validation的平均准确率，验证集合上使用early stoping。 
	- 试验结果如下表所示
	
	|模型| CNN1 | CNN2 | DPCNN | LSTM | ABLSTM | cLSTM | fastText 
	:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:
	|Ansj seg raw|0.8771|0.8820|0.7916|0.6571|0.6587|0.6872|0.925
	| Ansj seg keywords|0.8499|0.8655|0.7703|0.7459|0.6475|0.6790|0.91
	| HanLp seg raw| **0.8903** | **0.8906** | 0.7420|0.7568|**0.6994**|0.6355| **0.931**
	| HanLp seg nouns and verbs|0.8173|0.8278|0.7019|0.7140|0.6763|0.6520|0.86
	| Ansj raw seg with normalization|0.8709|0.8828|**0.7766**|**0.7602**|0.6766|**0.6937**|0.926
	| Ansj raw seg filter stopwords|0.8165|0.8248|0.7194|0.6594|0.6414|0.6923|0.873
	
- 结论
	- 不同预处理方式对最终分类结果影响非常大
	- 最好的表现主要集中在hanLp raw分词和Ansj with norm上

#### 模型调优(grid search)<br>
- CNN1
    - 调优空间
    > optimizer in "sgd" "adag" "adam"<br>
    learning_rate in 0.0001 0.0003 0.0006 0.001<br>
    output_channel 100 300 500 700

    - 最佳结果及其参数<br>
    模型使用hanLp raw seg，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross validation，根据验证集表现采用early stopping
    ```
        cross validation acc is 0.9251948051948051
        seq_len=14
        num_epoch=100
        learning_rate=0.0003
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        input_channel=1
        output_channel=300
        dropout=0.5
        kernel_sizes=2,3,4,5
        optimizer=adag
    ```

- CNN2
    - 调优空间
    > optimizer in "sgd" "adag"<br>
    conv1 in 200 300 400<br>
    conv2 in 200 300 400<br>
    linear_hidden_size in 100 300 500 700

    - 最佳结果及其参数<br>
    模型使用hanLp raw seg，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross
    ```
        cross validation acc is 0.9083116883116883
        seq_len=14
        num_epoch=100
        learning_rate=0.0003
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        linear_hidden_size=300
        kernel_sizes=2,3,4,5
        conv_channels=200,300
        dropout=0.5
        optimizer=adag
    ```

- DPCNN
    - 调优空间
    > optimizer in "sgd" "adag" "adam"<br>
    learning_rate in 0.0001 0.0003 0.0006 0.001<br>
    channel_size in 100 300 500 700

    - 最佳结果及其参数<br>
    模型使用Ansj raw seg with normalization，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross
    ```
        cross validation acc is 0.8724675324675324
        seq_len=14
        num_epoch=100
        learning_rate=0.0001
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        region_kernel_size=3
        channel_size=500
        conv_kernel_size=3
        pooling_kernel_size=3
        pooling_stride_size=2
        optimizer=sgd
    ```
    
- LSTM
    - 调优空间
    > optimizer in "sgd" "adag" "adam"<br>
    learning_rate in 0.0001 0.0003 0.0006 0.001<br>
    hidden_size in  100 300 500 700

    - 最佳结果及其参数<br>
    模型使用Ansj raw seg with normalization，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross
    ```
        cross validation acc is 0.882077922077922
        seq_len=14
        num_epoch=100
        learning_rate=0.001
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        hidden_size=500
        bidirectional=True
        num_layer=2
        batch_first=True
        dropout=0.5
        mean=True
        optimizer=adag
    ```

- ABLSTM
    - 调优空间
    > optimizer in "sgd" "adag" "adam"<br>
    learning_rate in 0.0003 0.0006 0.001<br>
    hidden_size in  100  300 500 700<br>
    attention_dim in 100  300 500 700

    - 最佳结果及其参数<br>
    模型使用hanLp raw seg，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross validation，根据验证集表现采用early stopping
    ```
        cross validation acc is 0.8849350649350649
        seq_len=14
        num_epoch=100
        learning_rate=0.001
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        hidden_size=100
        bidirectional=True
        num_layer=2
        batch_first=True
        dropout=0.5
        attention_dim=300
        optimizer=adag
    ```

- CLSTM 
    - 调优空间
    > optimizer in "sgd" "adag" "adam"<br>
    learning_rate in 0.0003 0.0006 0.001<br>
    hidden_size in  100 300 500 700<br>
    output_channel in 100 300 500 700

    - 最佳结果及其参数<br>
    模型使用Ansj raw seg with normalization，词向量使用mix，训练集是SMP2017 task1数据的train，测试集合是develop，训练集上用5-fold cross
    ```
        cross validation acc is 0.8854545454545455
        seq_len=14
        num_epoch=100
        learning_rate=0.0003
        is_verbose=False
        verbose_step=50
        use_valid=True
        weight_decay=0.0001
        batch_size=32
        emb_size=300
        n_class=31
        hidden_size=100
        bidirectional=True
        num_layer=1
        batch_first=True
        dropout=0.5
        kernel_sizes=2,3,4,5
        input_channel=1
        output_channel=700
        mean=True
        optimizer=adag
    ```
- 各模型最佳结果对照
	|模型| CNN1 | CNN2 | DPCNN | LSTM | ABLSTM | cLSTM | fastText
	:---|:---:|:---:|:---:|:---:|:---:|:---:| :---: |
    best acc| 0.9252|0.9083|0.8724 |0.8821 |0.8849|0.8854 | 0.931

#### 结论
- 预训练词向量质量对分类结果影响很大，在SMP2017 task1数据上 mix词向量明显好于ThuNews词向量
- 不同文本处理方式对分类结果影响也很大，比较好的两种处理方式是Hanlp raw seg和ansj with normalization
- 简单模型在改任务上表现较好，如CNN1和fastText
- adag在LSTM类模型上表现结果好

#### TODO
- [ ] baseline need more love
- [ ] static none-static对照试验
- [ ] 不同的embedding作为CNN的channel放在模型中
- [ ] 在pytorch中实现一个fastText
- [ ] 计算macro precision recall F和华南农大在SMP2017上面的benchmark做对比
- [ ] 尝试华南农大分享中提供的分类器
